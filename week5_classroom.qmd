---
output:
  html_document:
    df_print: paged
    code_download: TRUE
    toc: true
    toc_depth: 1
editor_options:
  chunk_output_type: console
---

```{r}
library(tidyverse)
library(palmerpenguins)
```

This is a catch-all week to cover a few useful things we haven't covered explicitly so far.

# ifelse

A useful function for recoding variables is ifelse().  It allows us to set the value of a varible based on some test:

```{r}
# ifelse(test, value if true, value if false)

x <- 1:10
x

ifelse(x > 5, 100, 0)
ifelse(x > 5, 100, x) # leave small values alone 

x <- sample(c(1:10, NA), replace=TRUE, 30)
x
x <- ifelse(is.na(x), 0, x)  # replace NA values with 0
x

# without ifelse:
x <- sample(c(1:10, NA), replace=TRUE, 30)
x
x[is.na(x)] <- 0
x
```


## Exercise

Make a new variable in the penguins data frame that labels penguins with body_mass_g > 4000 as "large" and other penguins as "small"

```{r}

```



# Factors

Factors are variables with text labels, but the set of values (called levels) that are allowed for the variable is limited, and the values optionally can have a specific order to them. Categorical data is stored in R as `factor` variables. You may ask why a special data structure is needed for categorical data, when we could just use `character` variables to represent the categories.

Let's say that you've conducted a survey on students' smoking habits. The possible responses are *Never*, *Occasionally*, *Regularly*, and *Heavy*. From 10 students, you get the following responses:

```{r}
smoke <- c("Never", "Never", "Heavy", "Never", "Occasionally","Never", "Never", "Regularly", "Regularly", "No")
```

Note that the last answer is invalid - `No` was not one of the four answers that were allowed for the question. You could use `table` to get a summary of how many answers of each type that you got:

```{r}
table(smoke)
```

But the categories are not presented in the correct order! There is a clear order between the different categories, *Never* \< *Occasionally* \< *Regularly* \< *Heavy*, but `table` doesn't present the results in that way. Moreover, R didn't recognize that `No` was an invalid answer, and treats it just the same as the other categories. This is where `factor` variables come in. They allow you to specify which values your variable can take, and the ordering between them (if any).

### Creating Factors

When creating a `factor` variable, you typically start with a `character`, `numeric` or `logical` variable, the values of which are turned into categories. To turn the `smoke` vector that you created in the previous section into a `factor`, you can use the `factor` function:

```{r}
smoke_factor <- factor(smoke)
smoke_factor
```

You can inspect the elements, and *levels*, i.e. values that the categorical variable takes, as follows:

```{r}
levels(smoke_factor)
```

We see two problems! First, we see that "No" is a level/category, but it was not listed on our survey. To fix this problem, we can decide the categories/levels a factor vector is allowed to take by specifying the `levels` parameter in the `factor()` function call:

```{r}
smoke_factor <- factor(
  smoke,
  # allowed levels
  levels = c("Never", "Heavy", "Occasionally", "Regularly") 
)

levels(smoke_factor)
smoke_factor
```

We see that "No" is no longer listed as a level, and has been replaced by `NA` in the factor vector `smoke_factor`.

However, we still have another problem - the categories are in the wrong order.

```{r}
barplot(table(smoke_factor))

smoke_factor <- factor(
  smoke,
  # allowed levels in some desired order
  levels = c("Never", "Occasionally", "Regularly", "Heavy") 
)

barplot(table(smoke_factor))
```

Now we see the categories are in an order that is more informative. However, we still have one more problem to fix. What if we wanted to compare smokers such that:

Never \< Occasionally \< Regularly \< Heavy

i.e. if we make conditional expressions such as smoke_factor \> Occasionally, then Never and Occasionally would evaluate to FALSE while Regularly and Heavy would evaluate to TRUE. This can be helpful to subset the data meaningfully or make comparisons when the order is meaningful in some manner.

Let's see how to do this with the `ordered` parameter within `factor()`

```{r}
smoke_factor <- factor(
  smoke,
  # create allowed levels in some desired order
  levels = c("Never", "Occasionally", "Regularly", "Heavy"),
  # logical flag to determine if the levels should be regarded as ordered (in the order given) for any comparisons
  ordered = TRUE
  )

smoke_factor
```

Notice how the level information is presented differently this time to indicate possible comparisons between categories.

```{r}
smoke_factor
smoke_factor > "Occasionally"

# how many survey respondents smoke more than Occasionally
sum(smoke_factor > "Occasionally", na.rm = TRUE)
```

To recap, you can control the order in which the levels are presented by choosing which order we write them in in the `levels` argument. The `ordered = TRUE` argument specifies that the order of the variables is *meaningful*. `ordered = TRUE` can be excluded in cases where you wish to specify the order in which the categories should be presented purely for presentation purposes (e.g., when specifying whether to use the order `Male/Female/Other` or `Female/Male/Other`).

Also, note that the `No` answer now became an `NA`, which in the case of `factor` variables represents both missing observations and invalid observations. To find the values of **`smoke`** that became `NA` in **`smoke_factor`** you can use `which` and `is.na`:

```{r}
smoke
smoke_factor
is.na(smoke_factor)
which(is.na(smoke_factor))
smoke[which(is.na(smoke_factor))]
```

By checking the original values of the `NA` elements, you can see if they should be excluded from the analysis or recoded into a proper category (`No` could for instance be recoded into `Never`).

### Changing factor levels

When we created `smoke_factor`, one of the elements became an `NA`. `NA` was however not included as a level of the `factor`. Sometimes it is desirable to include `NA` as a level, for instance when you want to analyse rows with missing data. This is easily done using the `addNA` function:

Note: we'll do this with the same smoke variable we've been using, but we typically wouldn't want to add an explicit category for missing with an ordered factor, because we don't know where in the order it should belong -- as missing, it's not included in the order, but as a category, it has to fall in the order.

```{r}
levels(smoke_factor)
smoke_factor <- addNA(smoke_factor)
levels(smoke_factor)
smoke_factor
```

If you wish to change the name of one or more of the `factor` levels, you can do it directly via the `levels` function. For instance, we can change the name of the `NA` category, which is the 5th level of `smoke_factor`, as follows:

```{r}
levels(smoke_factor)
levels(smoke_factor)[5]
levels(smoke_factor)[5] <- "Invalid answer"
levels(smoke_factor)
smoke_factor
```


### Combining levels

Finally, `levels` can be used to merge categories by replacing their separate names with a single name. For instance, we can combine the smoking categories *Occasionally*, *Regularly*, and *Heavy* to a single category named *Yes*. Assuming that these are first, second and third in the list of names (as will be the case if you've run the last code chunk above), here's how to do it:

```{r}
# create our factor vector as usual
smoke_factor <- factor(
  smoke,
  levels = c("Never","Occasionally","Regularly","Heavy"),
  ordered = TRUE
  )
smoke_factor

# recode levels that are not "Never" to "Yes"
levels(smoke_factor)
levels(smoke_factor)[2:4] 
levels(smoke_factor)[2:4] <- "Yes"
levels(smoke_factor)
smoke_factor
table(smoke_factor)
```


### EXERCISE

Convert the vector below to a factor. Set the levels in an intentional order. Should ordered be set to TRUE here - why or why not?

Hint: use `table()` or `unique()` to find all the categories

```{r}
age_group <- c(
  "35-50",
  "25-34",
  "50-65",
  "65+",
  "18-24",
  "18-24",
  "50-65",
  "35-50",
  "50-65",
  "18-24",
  "18-24",
  "65+",
  "65+"
  )

# your code here               


```

### EXERCISE

Using the `cer` dataset, convert the columns `Number_of_STD_Diagnosis` into a factor.  Assume the missing values are 0 STDs.

```{r}
cer <- read_csv("data/cervical_cancer_data.csv")


```

### EXERCISE

Using the `cer` dataset, convert the column `Number_of_Pregnancies` to a factor. Then recode all `NA` values into "invalid".

```{r}
# make a factor

# add NA as an explicit level


# recode NA into "Invalid Answer"


```

## Factor Labels

Sometimes we have categorical variables that are encoded in our data with integer values -- for example, 0/1 indicator variables or answers like 1, 2, 3, 4, to a survey question.  It's helpful to change these numerical values to text labels so we don't confuse anything.  And we don't want to erroneously treat these variables as numerical when they're really categorical.  We can do this with factors as well.  

```{r}
my_study <- data.frame(id = c(1, 2, 3, 4, 5),
                       study_condition = c(0, 1, 0, 0, 1),
                       outcome = c(4, 6, 3, 4, 6))

table(my_study$study_condition)  # which is treatment and which is control?

my_study$study_condition <- factor(my_study$study_condition, 
                                   levels = c(0, 1),
                                   labels = c("control", "treatment"))
# make sure levels and labels are in the same order above, or, even better:
my_study$study_condition <- factor(my_study$study_condition, 
                                   labels = c("0"="control", "1"="treatment"))

table(my_study$study_condition) # much better!
```


# Missing Values

We've seen missing values a few times, but let's review to make sure we covered everything:

`NA` is the symbol for missing data; it can be used with any data type

```{r}
NA  
y <- c("dog", "cat", NA, NA, "bird")
y
x <- c(NA, 2, NA, 4, NA, 6, NA, 6, 6, 4)
x

is.na(y)
is.na(x)  
```

A common operation is to count how many missing values there are in a vector. We use the function `is.na()` to get TRUE when the value is `NA` and FALSE otherwise. Then we sum that result; this works because TRUE converts to 1 and FALSE converts to 0. So it counts the number of missing values (the number of TRUEs).

```{r}
sum(is.na(x))

sum(c(TRUE, FALSE))
x
sum(is.na(x))  
```

Different functions handle missing values in different ways. Most commonly, you'll get an answer of `NA` unless you tell the function to remove or exclude the missing values in the calculation.

```{r}
mean(x)
mean(x, na.rm=TRUE)
```

If we don't want the missing rows included in our results above when we were selecting rows of penguins:

```{r}
penguins$bill_length_mm

is.na(penguins$bill_length_mm)


!is.na(penguins$bill_length_mm)  # ! is not


penguins[ !is.na(penguins$bill_length_mm)   ,  ]

dim(penguins)

# not missing bill length AND bill length < 34

!is.na(penguins$bill_length_mm) &  penguins$bill_length_mm < 34

penguins[!is.na(penguins$bill_length_mm) & penguins$bill_length_mm < 34, ]
dim(penguins[!is.na(penguins$bill_length_mm) & penguins$bill_length_mm < 34, ])

penguins[penguins$bill_length_mm < 34, ]
dim(penguins[penguins$bill_length_mm < 34, ])
```

The function `complete.cases()` can be used to find which rows have no missing values at all:

```{r}
complete.cases(penguins)

penguins[ !complete.cases(penguins) , ]


dim(penguins)

penguins[complete.cases(penguins), ] ## effectively drops rows with any missing values
dim(penguins[complete.cases(penguins), ])
```

The function `na.omit()` can be used to shorten the above calls, it directly returns the subset of data with complete cases.

```{r}
na.omit(penguins) # is the same as code chunk above
dim(na.omit(penguins))
```

## EXERCISE

How many missing values in `penguins$bill_depth_mm`?

What is the mean of the non-missing values of `penguins$bill_depth_mm`?

```{r}
penguins$bill_depth_mm 
is.na(penguins$bill_depth_mm)
sum(is.na(penguins$bill_depth_mm))


is.na(penguins$bill_depth_mm) # missing
!is.na(penguins$bill_depth_mm) # not missing
penguins$bill_depth_mm[ !is.na(penguins$bill_depth_mm) ] # index with not missing
mean(penguins$bill_depth_mm[ !is.na(penguins$bill_depth_mm) ]) # mean of not missing

# same as
mean(penguins$bill_depth_mm, na.rm=TRUE)
```

Challenge: Select the rows from penguins where `penguins$bill_depth_mm` is missing.

```{r}

```

Challenge: What is the mean of non-missing values of `penguins$bill_depth_mm` for penguins of species Gentoo?

```{r}

```


## Count missing values across variables

What if we want to get a look at the number of missing values across our dataset?

One option is the summary() function:

```{r}
summary(penguins)
```

This gives us more than the missing counts, but it does include it.

We could also count them explicitly.  The across() function with summarize() lets us do the same thing to all variables.  We need to use an anonymous function to do this because we need to call both sum() and is.na().  

Just like with other function in R, we declare a input argument -- here, "x", and then use x to stand in for each variable in the expression we want to compute for each column:

```{r}
penguins %>%
  summarize(across(everything(), \(x) sum(is.na(x))))
```

There's another syntax for anonymous functions that you might see instead:

```{r}
penguins %>%
  summarize(across(everything(), ~sum(is.na(.x))))
```

They both do the same thing.



# Correlation

Calculating correlations in R can be done using the `cor()` command. The simplest way to use the command is to specify two input arguments `x` and `y`, each one corresponding to one of the variables.

```{r}
cor(penguins$bill_depth_mm, penguins$bill_length_mm)
```

However, the `cor()` function is a special case. It doesn't have an `na.rm` argument, because the story becomes a lot more complicated when more than one variable is involved. What it does have is an argument called `use` which does roughly the same thing, but you need to think little more carefully about what you want this time. Type `?cor` in the console and read through the `use` parameter options.

With just two variables, if we want to exclude missing values, then "pairwise.complete.obs" and "complete.obs" will do the same thing:

```{r}
cor(penguins$bill_depth_mm, penguins$bill_length_mm, 
    use="pairwise.complete.obs")
cor(penguins$bill_depth_mm, penguins$bill_length_mm, 
    use="complete.obs")

# we can abbreviate
cor(penguins$bill_depth_mm, penguins$bill_length_mm, 
    use="pairwise")
cor(penguins$bill_depth_mm, penguins$bill_length_mm, 
    use="p")
```

The difference comes when we compute a correlation matrix of multiple variables:

```{r}
cor(penguins[, 3:6])
cor(penguins[, 3:6], use="pairwise")
cor(penguins[, 3:6], use="pairwise") %>% round(2)
```

With penguins, all of the missing values are in the same observations, so we won't get a different result.  Let's look at a different data frame:

```{r}
missing_df <- data.frame(a = c(1:10),
                         b = c(NA, 4, NA, 5, NA, 6, 7, 8, 10, 12),
                         c = c(1, NA, 2, NA, 10, 20, 30, 40, 60, 80), 
                         d = c(1, 4, 7, 9, 5, NA, NA, 6, 3, 4))

cor(missing_df, use="pairwise") %>% round(2)

complete.cases(missing_df)
cor(missing_df, use="complete") %>% round(2)  # only using 3 obs

```

There are also different types of correlation.  You can choose the correlation method from "pearson", "kendall", "spearman".  Pearson is the default and is appropriate for continuous data that is roughly normally distributed (more on this next week).  Kendall and Spearman are rank-based correlations that work well for skewed data - instead of computing the correlation between the absoute values of the varibles, they rank order the values of eac variable, and then compute a correlation between the ranks.  

```{r}
cor(penguins$bill_depth_mm, penguins$bill_length_mm, 
    use="pairwise")
cor(penguins$bill_depth_mm, penguins$bill_length_mm, 
    use="pairwise", method="kendall")
cor(penguins$bill_depth_mm, penguins$bill_length_mm, 
    use="pairwise", method="spearman")
```




# Odds Ratios

A common statistic computed in clinical studies is an odds ratio.  This compares how likely something is for one group to another.  To compute this, we first need to compute a likelihood (odds) for a specific group for a given event happening.  Unless we're working with a more complicated statistical model, this is generally just the proportion of observations in a group that meet some criteria.  

Let's look at the likelihood that a penguin is heavier than 4kg by sex

```{r}
# overall
penguins %>%
  mutate(heavy = body_mass_g > 4000) %>%
  summarize(heavy_prop = sum(heavy, na.rm=TRUE)/sum(!is.na(heavy))) # count not missing instead of n()

penguins %>%
  mutate(heavy = body_mass_g > 4000) %>%
  group_by(sex) %>%
  summarize(heavy_prop = sum(heavy, na.rm=TRUE)/sum(!is.na(heavy))) # count not missing instead of n()
```

This is a time when it might be more convenient to use base R:

```{r}
male_prop <- sum(penguins$body_mass_g[penguins$sex == "male" & !is.na(penguins$sex)] > 4000)/
  sum(!is.na(penguins$body_mass_g[penguins$sex == "male" & !is.na(penguins$sex)]))

female_prop <- sum(penguins$body_mass_g[penguins$sex == "female" & !is.na(penguins$sex)] > 4000)/
  sum(!is.na(penguins$body_mass_g[penguins$sex == "female" & !is.na(penguins$sex)]))

# or pull them out of our result above:
group_props <- penguins %>%
  mutate(heavy = body_mass_g > 4000) %>%
  filter(!is.na(sex)) %>%  ## drop the missing
  group_by(sex) %>%
  summarize(heavy_prop = sum(heavy, na.rm=TRUE)/sum(!is.na(heavy))) 

male_prop <- group_props$heavy_prop[group_props$sex == "male"]
male_prop
female_prop <- group_props$heavy_prop[group_props$sex == "female"]
female_prop
```

These are the individual odds of a male and female penguin being > 4kg.  The odds ratio is the ratio of these two values (one divided by the other):

```{r}
male_prop/female_prop
```

Male penguins are 1.8 times more likely to be > 4kg than female penguins.  For every 1 female penguin > 4kg, there are 1.8 male penguins > 4kg.

Computed the other way:

```{r}
female_prop/male_prop
```

Female penguins are about half (.54) as likely as male penguins to be > 4kg.  




