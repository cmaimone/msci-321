---
output:
  html_document:
    df_print: paged
    code_download: TRUE
    toc: true
    toc_depth: 1
editor_options:
  chunk_output_type: console
---

## Setup

```{r}
library(tidyverse)
library(palmerpenguins)
```

# Recap

## Reading in a Data File

```{r}
cer <- read_csv("data/cervical_cancer_data.csv")
spec(cer)
```

Note we used the `read_csv` function from the package `{readr}` this time. Run `spec(cer)` to see what changed with the import (run `str(read.csv("data/cervical_cancer_data.csv"))` for comparison if needed).

## Working with variables (columns)

```{r}
cer$Age_of_Respondents
mean(cer$Age_of_Respondents)

# making new variables
cer$is_minor <- cer$Age_of_Respondents < 18
```

## Indexing dataframes

```{r}
# by position: df[rows_indices, col_indices]
cer[, c(2,5)]
cer[1:10, c(2,5)]

# by column name
cer[,c("Age_of_Respondents", "Is_Diagnosed_with_STDs")]
```

## Select: choose columns

The `select()` function lets us choose which columns (or variables) we want to keep in our data. This is an alternative to the base R expressions above.

```{r}
cer %>% 
  select(Age_of_Respondents > 18)
```

You can also select columns based on conditions such as `starts_with` , `ends_with`, or `contains`

```{r}
cer %>% 
  select(starts_with("Time_Since")) %>% 
  names
```

## Mutate: modify columns

`mutate()` is used to both change the values of an existing column and make a new column.

```{r}
cer %>% 
  mutate(is_senior = Age_of_Respondents > 65)
```

# Choosing observations/rows

With base R, we know we can index a data frame by row position:

```{r}
cer[1:20,]
```

However, suppose we want to choose rows from a data frame that might meet a specific condition. For example, choose all data for patients aged greater than 65, or select all sales items that were sold in the month of December.

Typically, we use Boolean expressions to choose the ROWS (not the columns) because we want to select which particular observations meet some criteria.

If we have a Boolean vector (`TRUE` and `FALSE` values) that is the same length as the number of rows or columns, we can use it to select data.

For example, let's suppose you want to find respondents in the `cer` dataset who are above the age of 18

```{r}
cer$Age_of_Respondents
cer$Age_of_Respondents > 18
cer[cer$Age_of_Respondents > 18,]

# cer$is_minor was created above
cer$is_minor
cer[cer$is_minor, ]
```

The command above works because R selects the values which evaluated to TRUE and discards the values that evaluated to FALSE.

What if we wanted to know how many observations meet a specific condition?  We can use `sum()` to count TRUE values (because TRUE = 1 and FALSE = 0):

```{r}
sum(cer$Age_of_Respondents > 18)
sum(cer$is_minor)

# count the opposite by using ! (not)
sum(!cer$is_minor)
```


Let's see an example with the penguins data frame: Select rows where penguin bill length is greater than 34.

```{r}
penguins$bill_length_mm
penguins$bill_length_mm < 34
penguins[penguins$bill_length_mm < 34] # what happened here?
penguins[penguins$bill_length_mm < 34,]
```

## dplyr method - Filter: choose rows

We can also use tidyverse / dplyr functions to choose rows.

To choose which rows should remain in our data, we use `filter()`. As with `[]`, we write expressions that evaluate to TRUE or FALSE for each row. Like `select()`, we can use the column names without quotes.

For example, let's suppose you want to find respondents in the `cer` dataset who are above the age of 18

```{r}
filter(cer, Age_of_Respondents > 18)
```

Alternatively, the preferred syntax is:

```{r}
cer %>% 
  filter(Age_of_Respondents > 18)
```

If the column itself contains TRUE/FALSE values, then you can also select TRUE values as:

```{r}
cer %>% 
  filter(Is_Diagnosis_Cancer)
```

Similarly, select rows where penguin bill length is greater than 34.

```{r}
penguins %>% 
  filter(bill_length_mm > 34)
```

### EXERCISE

Select the Age_of_Respondents, Smoking_in_Years, and Smoking_in_Packs_per_Year columns for respondents who smoke. Make use of the `%>%` operator.

```{r}

```

## Chaining multiple conditions together

Remember, any expression that evaluates to TRUE or FALSE for each row will work to choose rows.

For example, say we want to choose observations where the respondent is a smoker and a minor

```{r}
# condition 1 -- respondent is a smoker
cer$Is_Smoking

# condition 2 - respondent is a minor
cer$Age_of_Respondents < 18

# combine both conditions with AND
cer$Is_Smoking & cer$Age_of_Respondents < 18

# use the above expression to choose ROWS from cer
cer[cer$Is_Smoking & cer$Age_of_Respondents < 18, ] # base R
```

We can also use dplyr filter to do the same

```{r}
cer %>% 
  filter(Is_Smoking & Age_of_Respondents < 18)

# alternative expression
cer %>% 
  filter(Is_Smoking,
         Age_of_Respondents < 18)

# also 
cer %>% 
  filter(Is_Smoking) %>% 
  filter(Age_of_Respondents < 18)
```

By default, if multiple conditions are provided to filter, it will join them logically with AND.

To join conditions with OR, we would do the following

```{r}
cer %>% 
  filter(cer$Is_Smoking | cer$Age_of_Respondents < 18)
```

## EXERCISE

Select rows from penguins where bill length is less than 34 or greater than 58.

```{r}

```

## EXERCISE

How many smokers were diagnosed with cancer in the cer dataset?

How many non-smokers were diagnosed with cancer in the cer dataset?

```{r}

```

## dplyr: Summarize

We use `mutate()` when we want the output to have the same length as the input. In other words, we use `mutate()` when we're operating on the individual elements in a vector - we want a value for every row in the data.

When we want to condense multiple values down to a single (or a few values), such as taking the mean or standard deviation of a vector, we use summarize instead:

```{r}
police %>% 
  mutate(vehicle_age = 2017 - vehicle_year) %>% # computing a new variable first
  summarize(mean_vehicle_age = mean(vehicle_age))
```

Note that even though there's just one value, we get a tibble returned. This is expected within the tidyverse.

We can compute more than one summary measure at the same time:

```{r}
police %>% 
  mutate(vehicle_age = 2017 - vehicle_year) %>% # computing a new variable first
  summarize(
    mean_vehicle_age = mean(vehicle_age),
    sd_vehicle_age = sd(vehicle_age),
    min_date = min(date),
    max_date = max(date)
    )
```

We get one column per summary variable we create. Once we group below, we'll see why we get the output in columns instead of rows.

### EXERCISE

Use summarize to compute the `min()` and `max()` `vehicle_year`

```{r}

```

## Across

If we want to apply the same summary functions to multiple columns in our data frame, we can write out all of the summary commands explicitly, or we can use `across()` to select which variables to summarize with which functions.

Let's use the `n_distinct()` function to count the number of distinct values in each column (`n_distinct(x)` is the same as `length(unique(x))`. This will help us see which columns don't have useful information because every value is the same.

`across()` selects columns using the helper functions you could give to `select()` directly. We'll use `everything()` here to select all columns.

```{r}
cer %>%
  summarize(across(everything(), n_distinct))
```

If you wanted to select columns using their names, put them in a vector (so it's a single input argument):

```{r}
cer %>%
  summarize(across(c(Age_of_Respondents, Number_of_Sexual_Partners, Number_of_Pregnancies), 
                   n_distinct))
```

If we want to apply multiple functions:

```{r}
cer %>%
  na.omit() %>% 
  summarize(across(where(is.numeric), ## select columns that are not of type character
                   list(min, max))) %>% # take the min and max of each column
  View()
```

To fix the names in the output, explicitly name our summary functions in the list:

```{r}
cer %>%
  na.omit() %>%
  summarize(across(!where(is.character), ## select columns that are not of type character
                   list(min_val=min, max_val=max))) %>% # take the min and max of each column
  View()
```

There are other options for output naming patterns available too.

## dplyr: Group_by

When we want to compute summary measures or do other computation on groups in our data (as defined by some grouping variable), we can explicitly group our tibble into subgroups. This isn't very useful by itself, but it is often combined with `summarize()` to compute summary measures by group.

First, what if we just group our data by a specific column:

```{r}
cer %>%
  group_by(Is_Diagnosed_with_STDs)
```

When we print this in the console,

```         
# A tibble: 835 Ã— 36
# Groups:   Is_Diagnosed_with_STDs [3]
   Age_of_Respondents Number_of_Sexual_Partners First_Sexual_Intercourse
                <dbl>                     <dbl>                    <dbl>
 1                 18                         4                       15
 2                 15                         1                       14
 3                 34                         1                       NA
 4                 52                         5                       16
 5                 46                         3                       21
 6                 42                         3                       23
 7                 51                         3                       17
 8                 26                         1                       26
 9                 45                         1                       20
10                 44                         3                       15
...
```

we see that it tells us that the tibble (data frame) is grouped by "Is_Diagnosed_with_STDs", and that there are three groups. It doesn't rearrange the rows, it just keeps track of the groups for us.

Now, let's combine it with summarize.

```{r, eval=TRUE}
cer %>% 
  group_by(Is_Diagnosed_with_STDs) %>% 
  summarise(
    mean_age = mean(Age_of_Respondents),
    sd_age = sd(Age_of_Respondents)
  )
```

Now we get one row for each group, and one column for each summary measure.

We can also group by multiple columns, and we'll get all of the combinations of values present across the columns:

```{r}
cer %>% 
  group_by(Is_Diagnosed_with_STDs, Is_Smoking) %>% 
  summarise(
    mean_age = mean(Age_of_Respondents),
    sd_age = sd(Age_of_Respondents)
  )
```

We are getting extra information alerting us to the fact that our output is grouped. If we don't want the groups in place anymore, we can ungroup(). Usually this doesn't matter though if we're just printing output to the screen.

```{r}
cer %>% 
  group_by(Is_Diagnosed_with_STDs, Is_Smoking) %>% 
  summarise(
    mean_age = mean(Age_of_Respondents),
    sd_age = sd(Age_of_Respondents)
  ) %>% 
  ungroup()
```

Usually this would come up after more complicated operations, and often after computing summary measures by group.

### EXERCISE

Compute the `min()` and `max()` `Age_of_Respondents` for each count of `Number_of_Pregnancies`.

```{r}

```

## Slicing

One operation we could do with a grouped tibble is to select just certain rows from each group. For example, we could use the `slice()` function to select the first row from each group:

```{r}
cer %>%
  select(Number_of_Pregnancies, everything()) %>%  # to reorder columns for output
  group_by(Number_of_Pregnancies) %>%
  slice(1)
```

If you look at this output in the console, you'll see the resulting tibble still has groups in it. This is a case where you might want to ungroup:

```{r}
cer %>%
  select(Number_of_Pregnancies, everything()) %>%  # to reorder columns for output
  group_by(Number_of_Pregnancies) %>%
  slice(1) %>% 
  ungroup()
```

## Arrange

Finally, we come to `arrange()`, which is how we sort the rows in our data. We would mostly use this when viewing our data, but it's also useful when we need to compute a time series (lags and leads in the data), when we want to select just a few rows from each group, or any other order-sensitive transformations on our data.

```{r}
cer %>% 
  arrange(Age_of_Respondents) %>% 
  View()
```

To sort in reverse order, wrap the column name in `desc()`.

```{r}
cer %>% 
  arrange(desc(Age_of_Respondents)) %>% 
  View()

# optionally-
cer %>% 
  arrange(-Age_of_Respondents) %>% 
  View()
```

Arrange by multiple columns, in order:

```{r}
cer %>% 
  arrange(-Age_of_Respondents, Number_of_Sexual_Partners) %>% 
  View()
```

## Count

A bonus function that I use frequently: `count()`. It's how you'd get output similar to `table()`

By itself, it counts the number of rows:

```{r}
cer %>%
  count()
```

If you supply the name of a column, it makes a table:

```{r}
cer %>%
  count(Number_of_STD_Diagnosis)
```

This is the same result as if you grouped the data first:

```{r}
cer %>%
  group_by(Number_of_STD_Diagnosis) %>%
  count()
```

You can group by multiple columns directly with count:

```{r}
cer %>%
  count(Is_Smoking, Number_of_STD_Diagnosis)
```

## Tabyl (janitor)
